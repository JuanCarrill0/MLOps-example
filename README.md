# MLOps Example â€“ ImplementaciÃ³n prÃ¡ctica en IngenierÃ­a de Software

Este proyecto es una **implementaciÃ³n funcional de MLOps (Machine Learning Operations)**, aplicada al contexto de la **ingenierÃ­a de software**.  
Su objetivo es demostrar cÃ³mo automatizar el ciclo de vida completo de un modelo de Machine Learning: desde el entrenamiento hasta el despliegue y la monitorizaciÃ³n, usando herramientas abiertas y pipelines reproducibles.

---

## Â¿QuÃ© hace este programa?

Este sistema entrena un modelo de **regresiÃ³n lineal** para predecir el **precio estimado de una vivienda** a partir de variables simples:
- NÃºmero de habitaciones (`rooms`)
- Ãrea en metros cuadrados (`area`)
- AntigÃ¼edad (`age`)

Incluye:
- GeneraciÃ³n de datos sintÃ©ticos (si no hay dataset)
- Entrenamiento y evaluaciÃ³n del modelo
- API REST (con FastAPI) para realizar predicciones
- Control de versiones de datos y modelos con DVC
- Tracking de experimentos con MLflow
- ContainerizaciÃ³n con Docker para deployment

---

## ImplementaciÃ³n MLOps del Proyecto

### Stack TecnolÃ³gico MLOps

| Herramienta | PropÃ³sito | ImplementaciÃ³n |
|-------------|-----------|----------------|
| **MLflow** | Experiment Tracking & Model Registry | Registro automÃ¡tico de mÃ©tricas y modelos |
| **DVC** | Data Version Control & Pipeline Management | Pipeline declarativo y versionado de datos |
| **Docker** | ContainerizaciÃ³n & Deployment | Imagen lista para producciÃ³n |
| **FastAPI** | Model Serving & API | REST API con validaciÃ³n automÃ¡tica |
| **scikit-learn** | Machine Learning Framework | Modelo de regresiÃ³n lineal |
| **GitHub** | Source Code Management | Control de versiones y colaboraciÃ³n |

### Arquitectura MLOps

```mermaid
graph TB
    A[Datos Raw] --> B[DVC Pipeline]
    B --> C[Preprocessing]
    C --> D[Training]
    D --> E[MLflow Tracking]
    D --> F[Model Artifacts]
    F --> G[Evaluation]
    F --> H[Docker Image]
    H --> I[FastAPI Service]
    I --> J[Production API]
    
    E --> K[MLflow UI]
    G --> L[Metrics Dashboard]
```

### 1. MLflow - Experiment Tracking & Model Registry

**UbicaciÃ³n**: Integrado en `src/train.py`

```python
# Tracking automÃ¡tico de experimentos
mlflow.set_experiment('mlops-example')
with mlflow.start_run():
    score = model.score(X_test, y_test)
    mlflow.log_metric('r2_score', float(score))
    mlflow.log_artifact('models/model.pkl')
```

**CaracterÃ­sticas implementadas**:
- âœ… **Experiment Tracking**: Registro automÃ¡tico de mÃ©tricas (RÂ² score)
- âœ… **Model Registry**: Versionado de modelos con metadatos
- âœ… **Artifact Storage**: Almacenamiento de modelos entrenados
- âœ… **Reproducibilidad**: Tracking completo de parÃ¡metros y resultados

**Uso**:
```bash
# Iniciar MLflow UI
mlflow ui
# Acceder a: http://localhost:5000
```

### 2. DVC - Data Version Control & Pipeline Management

**UbicaciÃ³n**: `dvc.yaml`

```yaml
stages:
  preprocess:    # Etapa de preprocesamiento de datos
    cmd: python src/train.py --preprocess-only
    outs:
      - data/processed/housing.csv
      
  train:         # Etapa de entrenamiento del modelo
    cmd: python src/train.py
    deps:
      - data/processed/housing.csv
    outs:
      - models/model.pkl
      
  evaluate:      # Etapa de evaluaciÃ³n y mÃ©tricas
    cmd: python src/evaluate.py
    deps:
      - models/model.pkl
      - data/processed/housing.csv
```

**CaracterÃ­sticas implementadas**:
- âœ… **Pipeline Declarativo**: DefiniciÃ³n clara de dependencias entre etapas
- âœ… **Reproducibilidad**: EjecuciÃ³n determinÃ­stica del pipeline
- âœ… **Incremental Builds**: Solo re-ejecuta etapas con cambios
- âœ… **Data Lineage**: Tracking de dependencias de datos

**Uso**:
```bash
# Ejecutar pipeline completo
dvc repro

# Ejecutar solo una etapa
dvc repro train

# Ver estado del pipeline
dvc dag
```

### 3. Docker - ContainerizaciÃ³n & Deployment

**UbicaciÃ³n**: `Dockerfile`

```dockerfile
FROM python:3.10-slim
WORKDIR /app

# InstalaciÃ³n de dependencias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copia de cÃ³digo y modelos
COPY src/ ./src
COPY models/ ./models

# ConfiguraciÃ³n del servicio
EXPOSE 8000
CMD ["uvicorn", "src.predict:app", "--host", "0.0.0.0", "--port", "8000"]
```

**CaracterÃ­sticas implementadas**:
- âœ… **Portabilidad**: Mismo entorno en desarrollo y producciÃ³n
- âœ… **Consistency**: Elimina problemas de dependencias
- âœ… **Scalability**: FÃ¡cil escalado horizontal
- âœ… **Isolation**: EncapsulaciÃ³n completa del entorno

**Uso**:
```bash
# Construir imagen
docker build -t mlops-example .

# Ejecutar contenedor
docker run -p 8000:8000 mlops-example

# Acceder a API: http://localhost:8000/docs
```

### 4. FastAPI - Model Serving & API

**UbicaciÃ³n**: `src/predict.py`

```python
# API REST con validaciÃ³n automÃ¡tica
@app.post('/predict')
def predict(body: RequestBody):
    """Endpoint para predicciones de precios de viviendas"""
    if model is None:
        raise HTTPException(status_code=503, detail='Model not available')
    
    x = np.array([[body.rooms, body.area, body.age]])
    pred = model.predict(x)[0]
    return {'predicted_price': float(pred)}

@app.get('/health')
def health():
    """Health check para monitoreo"""
    return {'status':'ok', 'model_loaded': model is not None}
```

**CaracterÃ­sticas implementadas**:
- âœ… **REST API**: Endpoints para predicciones en tiempo real
- âœ… **Data Validation**: ValidaciÃ³n automÃ¡tica con Pydantic
- âœ… **Auto Documentation**: Swagger UI automÃ¡tico
- âœ… **Health Monitoring**: Endpoints para verificar estado del servicio
- âœ… **Error Handling**: Manejo robusto de errores

### ğŸ“ 5. Automated Testing & Evaluation

**UbicaciÃ³n**: `src/evaluate.py`

```python
# EvaluaciÃ³n automÃ¡tica del modelo
preds = model.predict(X_test)
r2 = r2_score(y_test, preds)                    # Coeficiente de determinaciÃ³n
mae = mean_absolute_error(y_test, preds)        # Error absoluto medio

print(f'R2: {r2:.4f}')    # Calidad del ajuste (0-1)
print(f'MAE: {mae:.2f}')  # Error promedio en unidades de precio
```

**MÃ©tricas implementadas**:
- âœ… **RÂ² Score**: Porcentaje de varianza explicada por el modelo
- âœ… **MAE**: Error absoluto medio en unidades monetarias
- âœ… **Automated Evaluation**: EvaluaciÃ³n automÃ¡tica post-entrenamiento
- âœ… **Reproducible Metrics**: Misma particiÃ³n de datos para comparabilidad

---

## Flujo MLOps Completo

### Pipeline de Desarrollo

1. **Desarrollo Local**:
   ```bash
   # 1. Entrenar modelo
   python src/train.py
   
   # 2. Evaluar rendimiento
   python src/evaluate.py
   
   # 3. Servir modelo localmente
   uvicorn src.predict:app --reload
   ```

2. **Pipeline DVC**:
   ```bash
   # Ejecutar pipeline completo
   dvc repro
   
   # Ver mÃ©tricas
   dvc metrics show
   
   # Visualizar pipeline
   dvc dag
   ```

3. **Experiment Tracking**:
   ```bash
   # Iniciar MLflow UI
   mlflow ui
   
   # Comparar experimentos en: http://localhost:5000
   ```

4. **Deployment**:
   ```bash
   # Construir y ejecutar contenedor
   docker build -t mlops-example .
   docker run -p 8000:8000 mlops-example
   
   # API disponible en: http://localhost:8000/docs
   ```

### Beneficios de la ImplementaciÃ³n MLOps

- **Reproducibilidad**: Experimentos completamente reproducibles con DVC + MLflow
- **Observabilidad**: Visibilidad completa del rendimiento del modelo
- **Deployment RÃ¡pido**: De desarrollo a producciÃ³n en minutos
- **Mantenibilidad**: CÃ³digo modular y bien documentado
- **Escalabilidad**: FastAPI + Docker para alta concurrencia
- **Confiabilidad**: Health checks y validaciÃ³n automÃ¡tica
- **Trazabilidad**: Historial completo de cambios en datos y modelos

### Arquitectura de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚   DVC Pipeline  â”‚â”€â”€â”€â–¶â”‚   MLflow Track  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Image   â”‚â—€â”€â”€â”€â”‚  Trained Model  â”‚â”€â”€â”€â–¶â”‚   Evaluation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estructura del proyecto

```
mlops-example/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Datos originales
â”‚   â””â”€â”€ processed/          # Datos procesados (versionados con DVC)
â”‚       â””â”€â”€ housing.csv     # Dataset sintÃ©tico de viviendas
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py            # Entrena modelo + MLflow tracking
â”‚   â”œâ”€â”€ evaluate.py         # EvalÃºa modelo (R2, MAE)
â”‚   â””â”€â”€ predict.py          # API FastAPI para predicciones
â”‚
â”œâ”€â”€ models/                 # Modelos entrenados (versionados)
â”‚   â””â”€â”€ model.pkl           # Modelo de regresiÃ³n lineal
â”‚
â”œâ”€â”€ mlruns/                 # Experimentos MLflow
â”‚   â”œâ”€â”€ 0/                  # Experimento por defecto
â”‚   â””â”€â”€ 461223848500336995/ # Experimento 'mlops-example'
â”‚
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ dvc.yaml                # Pipeline DVC (preprocess â†’ train â†’ evaluate)
â”œâ”€â”€ Dockerfile              # Imagen Docker para deployment
â””â”€â”€ README.md               # DocumentaciÃ³n completa
```

---

## âš™ï¸ Â¿CÃ³mo funciona el pipeline MLOps?

| Etapa | DescripciÃ³n | Herramienta |
|-------|--------------|--------------|
| 1ï¸âƒ£ Datos | GeneraciÃ³n o carga de datos (`data/processed/housing.csv`) | DVC |
| 2ï¸âƒ£ Entrenamiento | Entrena modelo de regresiÃ³n y lo guarda (`models/model.pkl`) | scikit-learn |
| 3ï¸âƒ£ EvaluaciÃ³n | Calcula mÃ©tricas de desempeÃ±o | sklearn.metrics |
| 4ï¸âƒ£ Versionamiento | Versiona datos y modelos | Git + DVC |
| 5ï¸âƒ£ Despliegue | Expone modelo vÃ­a API REST (FastAPI) | Docker + Uvicorn |
| 6ï¸âƒ£ CI/CD | Automatiza entrenamiento, evaluaciÃ³n y artefactos | GitHub Actions |

---

## InstalaciÃ³n y ejecuciÃ³n local

### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/JuanCarrill0/MLOps-example.git
cd mlops-example
```

### 2ï¸âƒ£ Crear entorno virtual e instalar dependencias
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# Linux/Mac
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Entrenar el modelo (con MLflow tracking)
```bash
python src/train.py
```
**Resultado**:
- âœ… `data/processed/housing.csv` (dataset sintÃ©tico)
- âœ… `models/model.pkl` (modelo entrenado)
- âœ… Experimento registrado en MLflow

### 4ï¸âƒ£ Evaluar el modelo
```bash
python src/evaluate.py
```
**Salida esperada**:
```
R2: 0.9999
MAE: 7.95
```

### 5ï¸âƒ£ Servir el modelo con API
```bash
uvicorn src.predict:app --reload
```
**API disponible en**:  
**Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)  
**Health Check**: [http://localhost:8000/health](http://localhost:8000/health)

**Ejemplo de predicciÃ³n**:
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"rooms": 3, "area": 75, "age": 10}'
```

### 6ï¸âƒ£ Visualizar experimentos MLflow
```bash
mlflow ui
```
**MLflow UI**: [http://localhost:5000](http://localhost:5000)

### 7ï¸âƒ£ Ejecutar pipeline DVC
```bash
# Pipeline completo
dvc repro

# Solo entrenamiento
dvc repro train

# Visualizar DAG
dvc dag
```

---

## Deployment con Docker

### ConstrucciÃ³n y ejecuciÃ³n
```bash
# Construir imagen
docker build -t mlops-example .

# Ejecutar contenedor
docker run -p 8000:8000 mlops-example
```

### VerificaciÃ³n del deployment
```bash
# Health check
curl http://localhost:8000/health

# PredicciÃ³n de prueba
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"rooms": 4, "area": 120, "age": 5}'
```

**Respuesta esperada**:
```json
{
  "predicted_price": 87543.21
}
```

---

## CI/CD con GitHub Actions

El archivo `.github/workflows/ci-cd.yml` ejecuta automÃ¡ticamente:
1. InstalaciÃ³n de dependencias  
2. Entrenamiento del modelo  
3. EvaluaciÃ³n de mÃ©tricas  
4. Subida del modelo entrenado como artefacto  

Cada vez que haces un `git push`, GitHub Actions lanza el pipeline y te mostrarÃ¡ los resultados en la pestaÃ±a **Actions** del repositorio.

---

## Control de versiones de datos y modelos con DVC

### InicializaciÃ³n y configuraciÃ³n
```bash
# Inicializar DVC en el proyecto
dvc init

# Agregar datos y modelos al tracking
dvc add data/processed/housing.csv
dvc add models/model.pkl

# Commitear los archivos .dvc
git add data/processed/housing.csv.dvc models/model.pkl.dvc .gitignore
git commit -m "Track data and model with DVC"
```

### ConfiguraciÃ³n de almacenamiento remoto (opcional)
```bash
# Google Drive
dvc remote add -d gdrive_remote gdrive://<FOLDER_ID>

# AWS S3
dvc remote add -d s3_remote s3://my-bucket/dvc-storage

# Subir datos al remoto
dvc push
```

### GestiÃ³n de versiones
```bash
# Restaurar versiÃ³n especÃ­fica
git checkout <commit-hash>
dvc checkout

# Ver diferencias entre versiones
dvc diff

# Obtener datos de versiÃ³n remota
dvc pull
```

---

## ï¿½ MLflow Tracking - GestiÃ³n de Experimentos

### Uso bÃ¡sico de MLflow
```bash
# Iniciar servidor MLflow
mlflow ui --host 0.0.0.0 --port 5000

# Acceder a la interfaz web
# http://localhost:5000
```

### Estructura de experimentos
```
mlruns/
â”œâ”€â”€ 0/                           # Experimento por defecto
â”œâ”€â”€ 461223848500336995/          # Experimento 'mlops-example'
â”‚   â”œâ”€â”€ meta.yaml               # Metadatos del experimento
â”‚   â””â”€â”€ <run-id>/               # Runs individuales
â”‚       â”œâ”€â”€ meta.yaml           # Metadatos del run
â”‚       â”œâ”€â”€ metrics/            # MÃ©tricas (R2, MAE, etc.)
â”‚       â”œâ”€â”€ params/             # ParÃ¡metros del modelo
â”‚       â”œâ”€â”€ tags/               # Tags del experimento
â”‚       â””â”€â”€ artifacts/          # Artefactos (modelos, plots)
```

### ComparaciÃ³n de experimentos
- **MÃ©tricas**: Comparar RÂ² score entre diferentes runs
- **Artifacts**: Descargar modelos de runs especÃ­ficos
---

## Concepto: Â¿QuÃ© es MLOps?

> **MLOps** (Machine Learning Operations) es la prÃ¡ctica que combina **Machine Learning**, **DevOps** y **Data Engineering** para automatizar y mantener el ciclo de vida de los modelos de aprendizaje automÃ¡tico en producciÃ³n.

### Principios MLOps implementados en este proyecto:

1. ** Reproducibilidad**: DVC + MLflow garantizan experimentos reproducibles
2. ** Observabilidad**: Tracking completo de mÃ©tricas y modelos
3. ** Automation**: Pipeline automatizado desde datos hasta deployment
4. ** Mantenibilidad**: CÃ³digo modular y bien documentado
5. ** Escalabilidad**: FastAPI + Docker para alta disponibilidad
6. ** Reliability**: Health checks y validaciÃ³n automÃ¡tica
7. **Traceability**: Historial completo de cambios y versiones

###  ComparaciÃ³n: Antes vs. DespuÃ©s de MLOps

| Aspecto | Sin MLOps ï¿½ | Con MLOps ğŸš€ |
|---------|---------------|---------------|
| **Reproducibilidad** | "Funciona en mi mÃ¡quina" | Pipeline determinÃ­stico |
| **Deployment** | Manual y propenso a errores | Automatizado con Docker |
| **Monitoreo** | Sin visibilidad del modelo | MÃ©tricas y logs centralizados |
| **Versionado** | CÃ³digo en Git solamente | Datos + modelos + cÃ³digo |
| **ColaboraciÃ³n** | DifÃ­cil compartir experimentos | Experimentos compartidos |
| **Rollback** | Complejo o imposible | Un comando con DVC |

---

##  PrÃ³ximos pasos para extender el MLOps

-  **Model Monitoring**: Integrar Evidently AI para detectar model drift
-  **Cloud Deployment**: Desplegar en GCP/AWS con Kubernetes
-  **CI/CD Pipeline**: GitHub Actions para deployment automÃ¡tico
-  **A/B Testing**: Framework para testing de modelos en producciÃ³n
-  **Model Security**: ValidaciÃ³n y sanitizaciÃ³n de inputs
-  **Advanced Metrics**: MÃ©tricas de negocio y performance monitoring

---

> "MLOps no es solo entrenar modelos; es llevarlos a producciÃ³n de forma confiable, reproducible y escalable."

---

## Concepto: Â¿QuÃ© es MLOps?

> **MLOps** (Machine Learning Operations) es la prÃ¡ctica que combina **Machine Learning**, **DevOps** y **Data Engineering** para automatizar y mantener el ciclo de vida de los modelos de aprendizaje automÃ¡tico en producciÃ³n.

En este ejemplo, MLOps permite:
- Automatizar el entrenamiento y evaluaciÃ³n del modelo  
- Versionar datasets y modelos con DVC  
- Desplegar un modelo como microservicio (FastAPI + Docker)  
- Asegurar reproducibilidad y trazabilidad con GitHub Actions  

---

## ğŸ§­ PrÃ³ximos pasos
- Implementar CI/CD completo con despliegue automÃ¡tico a Docker Hub o GCP

---
